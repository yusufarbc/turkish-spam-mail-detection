{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8b4014a",
   "metadata": {},
   "source": [
    "# Turkish Email Spam Detection with KNN\n",
    "\n",
    "**Goal:** Classify Turkish emails as spam or ham using K-Nearest Neighbors algorithm  \n",
    "**Dataset:** Turkish Spam V01 (825 emails)  \n",
    "vs optimize et profesyonel bir görünümü**Method:** KNN with optimized K value (K=3), 70/30 train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea1b575",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13c69e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import csv\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Create output directory\n",
    "Path(\"outputs/plots\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15becb99",
   "metadata": {},
   "source": [
    "## 2. KNN Algorithm Implementation\n",
    "\n",
    "KNN compares word frequencies using Euclidean distance and classifies based on K nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4248d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(text):\n",
    "    \"\"\"Count word frequencies in text\"\"\"\n",
    "    word_counts = {}\n",
    "    for word in text.split():\n",
    "        word_counts[word] = word_counts.get(word, 0) + 1\n",
    "    return word_counts\n",
    "\n",
    "def euclidean_difference(test_counts, training_counts):\n",
    "    \"\"\"Calculate Euclidean distance between word count vectors\"\"\"\n",
    "    total = 0\n",
    "    training_copy = training_counts.copy()\n",
    "    \n",
    "    for word in test_counts:\n",
    "        if word in training_copy:\n",
    "            total += (test_counts[word] - training_copy[word]) ** 2\n",
    "            del training_copy[word]\n",
    "        else:\n",
    "            total += test_counts[word] ** 2\n",
    "    \n",
    "    for word in training_copy:\n",
    "        total += training_copy[word] ** 2\n",
    "    \n",
    "    return total ** 0.5\n",
    "\n",
    "def get_class(neighbors):\n",
    "    \"\"\"Determine class based on majority vote\"\"\"\n",
    "    spam_count = sum(1 for label, _ in neighbors if label == \"spam\")\n",
    "    ham_count = len(neighbors) - spam_count\n",
    "    return \"spam\" if spam_count > ham_count else \"ham\"\n",
    "\n",
    "def knn_classifier(training_data, training_labels, test_data, K):\n",
    "    \"\"\"KNN classifier implementation\"\"\"\n",
    "    print(\"Running KNN Classifier...\")\n",
    "    result = []\n",
    "    \n",
    "    # Precompute training word counts\n",
    "    training_counts = [get_count(text) for text in training_data]\n",
    "    \n",
    "    for test_text in test_data:\n",
    "        test_counts = get_count(test_text)\n",
    "        \n",
    "        # Calculate distances to all training samples\n",
    "        distances = [\n",
    "            (training_labels[i], euclidean_difference(test_counts, training_counts[i]))\n",
    "            for i in range(len(training_data))\n",
    "        ]\n",
    "        \n",
    "        # Get K nearest neighbors\n",
    "        distances.sort(key=lambda x: x[1])\n",
    "        neighbors = distances[:K]\n",
    "        \n",
    "        # Predict class\n",
    "        result.append(get_class(neighbors))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b5e4f2",
   "metadata": {},
   "source": [
    "## 3. Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca7a3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = []\n",
    "with open(\"data/trspam.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        label = str(row[-1])\n",
    "        text = ''.join(row[:-1])\n",
    "        data.append([text, label])\n",
    "\n",
    "data = np.array(data[1:-1])  # Remove header and last row\n",
    "print(f\"Total emails: {len(data)}\")\n",
    "\n",
    "# Preprocess\n",
    "punc = string.punctuation\n",
    "with open(\"data/stopwords-tr.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    stopwords = f.read().splitlines()\n",
    "\n",
    "for record in data:\n",
    "    text = record[0]\n",
    "    for char in punc:\n",
    "        text = text.replace(char, \"\")\n",
    "    words = [word.lower() for word in text.split() if word not in stopwords]\n",
    "    record[0] = \" \".join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2e6237",
   "metadata": {},
   "source": [
    "## 4. Train and Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b423d2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "features = data[:, 0]\n",
    "labels = data[:, 1]\n",
    "training_data, test_data, training_labels, test_labels = train_test_split(\n",
    "    features, labels, test_size=0.30, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "# Try different K values to find the best one\n",
    "best_k = 24\n",
    "best_accuracy = 0\n",
    "print(\"Testing different K values...\")\n",
    "for k in [3, 5, 7, 9, 11, 15, 19, 24, 30]:\n",
    "    result = knn_classifier(training_data, training_labels, test_data, k)\n",
    "    accuracy = accuracy_score(test_labels, result)\n",
    "    print(f\"K={k}: Accuracy={accuracy*100:.2f}%\")\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_k = k\n",
    "\n",
    "print(f\"\\nBest K value: {best_k} with {best_accuracy*100:.2f}% accuracy\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Train with best K\n",
    "K = best_k\n",
    "result = knn_classifier(training_data, training_labels, test_data, K)\n",
    "accuracy = accuracy_score(test_labels, result)\n",
    "\n",
    "# Results\n",
    "print(\"=\"*50)\n",
    "print(f\"Training size: {len(training_data)} | Test size: {len(test_data)}\")\n",
    "print(f\"K value: {K}\")\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Correct: {int(accuracy*len(test_data))} | Wrong: {int((1-accuracy)*len(test_data))}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nDetailed Metrics:\")\n",
    "print(classification_report(test_labels, result, target_names=['ham', 'spam']))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(test_labels, result, labels=['ham', 'spam'])\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])\n",
    "plt.title(f'Confusion Matrix (K={K})', fontweight='bold')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/plots/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ Results saved to outputs/plots/confusion_matrix.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
